{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PySpark ML Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Getting Started with ML Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step is to initiate the `sc`, `spark`, and prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf, SparkContext\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().setMaster('local').setAppName('SparkBeginner')\n",
    "sc = SparkContext(conf=conf)\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table(name='links', database=None, description=None, tableType='TEMPORARY', isTemporary=True),\n",
       " Table(name='movies', database=None, description=None, tableType='TEMPORARY', isTemporary=True),\n",
       " Table(name='ratings', database=None, description=None, tableType='TEMPORARY', isTemporary=True),\n",
       " Table(name='tags', database=None, description=None, tableType='TEMPORARY', isTemporary=True)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load all the other movielens tables into spark context\n",
    "links_df = spark.read.csv('./input/ml-latest-small/links.csv', header=True)\n",
    "movies_df = spark.read.csv('./input/ml-latest-small/movies.csv', header=True)\n",
    "ratings_df = spark.read.csv('./input/ml-latest-small/ratings.csv', header=True)\n",
    "tags_df = spark.read.csv('./input/ml-latest-small/tags.csv', header=True)\n",
    "links_df.createOrReplaceTempView('links')\n",
    "movies_df.createOrReplaceTempView('movies')\n",
    "ratings_df.createOrReplaceTempView('ratings')\n",
    "tags_df.createOrReplaceTempView('tags')\n",
    "\n",
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step, before diving into ML pipeline, we will first prepare a joined spark dataframe with data from `tags`, `ratings`, and `movies`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_df = tags_df.withColumnRenamed('timestamp', 'tag_timestamp').join(\n",
    "    ratings_df.withColumnRenamed('timestamp', 'rating_timestamp'), on=['userId', 'movieId'], how='full_outer').join(\n",
    "    movies_df, on='movieId', how='left_outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `.withColumn()` and `.cast()` to force numeric data type\n",
    "\n",
    "Additionally, Spark ML does not take any **non-numeric** values.\n",
    "\n",
    "When dealing with features that's numeric but having dtype of \"string\", we need to force the type back to numeric (either `\"integer\"` or `\"double\"`). To do this, use `.cast()` method in combination with the `.withColumn()` method. It's important to note that .cast() works on columns, while .withColumn() works on DataFrames. The only argument that needs to be passed to `.cast()` is the kind of value to create, in string form. For integers, the argument is `\"integer\"` and for decimal numbers it's `\"double\"`.\n",
    "\n",
    "The call to `spark_column.cast()` inside a call to `spark_dataframe.withColumn()` can be used to overwrite the already existing column, for instance:\n",
    "\n",
    "```python\n",
    "df = df.withColumn('col', df.col.cast('double'))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[movieId: string, userId: string, tag: string, tag_timestamp: string, rating: string, rating_timestamp: string, title: string, genres: string]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+----+------+---------+---------+--------+\n",
      "|movieId|userId| tag|rating|  genre_1|  genre_2| genre_3|\n",
      "+-------+------+----+------+---------+---------+--------+\n",
      "| 117529|   103|null|     4|   Action|Adventure|   Drama|\n",
      "|   2161|   103|null|     3|Adventure| Children| Fantasy|\n",
      "|   2502|   104|null|     3|   Comedy|    Crime|    null|\n",
      "|    356|   104|null|     4|   Comedy|    Drama| Romance|\n",
      "|    616|   104|null|     3|Animation| Children|    null|\n",
      "|   1201|   105|null|     4|   Action|Adventure| Western|\n",
      "|  55247|   105|null|     5|   Action|Adventure|   Drama|\n",
      "|   5618|   105|null|     4|Adventure|Animation| Fantasy|\n",
      "|   5878|   105|null|     3|    Drama|  Romance|    null|\n",
      "|    608|   105|null|     4|   Comedy|    Crime|   Drama|\n",
      "|  61323|   105|null|     3|   Comedy|    Crime|   Drama|\n",
      "|  64839|   105|null|     4|    Drama|     null|    null|\n",
      "|  70286|   105|null|     4|  Mystery|   Sci-Fi|Thriller|\n",
      "|  72641|   105|null|     4|    Drama|     null|    null|\n",
      "|  81847|   105|null|     4|Animation| Children|  Comedy|\n",
      "|  96373|   105|null|     4|    Drama|     null|    null|\n",
      "|  47099|   106|null|     5|    Drama|     null|    null|\n",
      "|    150|    11|null|     5|Adventure|    Drama|    IMAX|\n",
      "|  56174|   111|null|     2|   Action|   Horror|  Sci-Fi|\n",
      "|  63992|   111|null|     1|    Drama|  Fantasy| Romance|\n",
      "+-------+------+----+------+---------+---------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ml_df = ml_df.withColumn('rating', ml_df.rating.cast('integer')).select('movieId', 'userId', 'tag', 'rating', 'title', 'genres')\n",
    "\n",
    "# split the genres by \"|\" to be used in .withColumn\n",
    "genre_cols = F.split(ml_df.genres, '[,|]')\n",
    "\n",
    "# take the first 3 genres from the \"genres\" list for each movie review\n",
    "ml_df = ml_df.withColumn(\n",
    "    'genre_1', genre_cols.getItem(0)).withColumn(\n",
    "    'genre_2', genre_cols.getItem(1)).withColumn(\n",
    "    'genre_3', genre_cols.getItem(2)).drop('title', 'genres')\n",
    "\n",
    "ml_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a `Pipeline` object for the pyspark machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `StringIndexer()` and `OneHotEncoder()` to transform the string-based categorical features\n",
    "\n",
    "As displayed above, the `rating` column is now interger type. For the `genre_n` columns, we need to instead transform them into `one-hot encoded` values. This can be done following 2 steps:\n",
    "\n",
    "1. Use the `StringIndexer()` from `pyspark.ml.features` module that uses an `Estimator` that maps strings to values and then a `Transformer` that creates mapped numeric values based on string column\n",
    "2. Use the `OneHotEncoder()` from same module that takes in the numeric values from the `StringIndexer()` and generates one-hot encoded columns for each feature category.\n",
    "\n",
    "**NOTE:**\n",
    "The above transformation of the input data is considered to be \"steps\" in a pyspark `Pipeline`; since this step needs to be stable for both model training and deploying, it is important that the pipeline stays the same and is reuseable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `.describe()` to obtain the descriptive statistics about any column of choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+-----------+------------------+------------------+---------+---------+\n",
      "|summary|           movieId|            userId|        tag|            rating|           genre_1|  genre_2|  genre_3|\n",
      "+-------+------------------+------------------+-----------+------------------+------------------+---------+---------+\n",
      "|  count|            102884|            102884|       3683|            102677|            102884|    86171|    57197|\n",
      "|   mean|19732.228918004745|328.01602775941836|       null| 3.363966613749915|              null|     null|     null|\n",
      "| stddev|35870.571562184814|183.15834507456145|       null|1.0903566711483974|              null|     null|     null|\n",
      "|    min|                 1|                 1|\"\"\"artsy\"\"\"|                 0|(no genres listed)|Adventure|Animation|\n",
      "|    max|             99992|                99|    zombies|                 5|           Western|  Western|  Western|\n",
      "+-------+------------------+------------------+-----------+------------------+------------------+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ml_df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a `StringIndexer()` and a `OneHotEncoder()` for each `genre_n` feature. Both of these 2 objects takes 2 major parameters:\n",
    "\n",
    "1. The `inputCol` is the name of the column you want to index or encode using the `Estimator`\n",
    "2. The `outputCol` is the name of the new column that the `Transformer` should create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create stringindexer and onehotencoder for each genre feature\n",
    "g1_indexer = StringIndexer(inputCol='genre_1', outputCol='genre_1_index', handleInvalid='skip') #\"keep\" puts NULL in separate bucket\n",
    "g1_encoder = OneHotEncoder(inputCol='genre_1_index', outputCol='genre_1_fact')\n",
    "g2_indexer = StringIndexer(inputCol='genre_2', outputCol='genre_2_index',  handleInvalid='skip')\n",
    "g2_encoder = OneHotEncoder(inputCol='genre_2_index', outputCol='genre_2_fact')\n",
    "g3_indexer = StringIndexer(inputCol='genre_3', outputCol='genre_3_index', handleInvalid='skip')\n",
    "g3_encoder = OneHotEncoder(inputCol='genre_3_index', outputCol='genre_3_fact')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a final ML-ready data wrapper step for the `Pipeline`\n",
    "\n",
    "The last step in the `Pipeline` is to combine all of the columns containing our features **into a single column**. This has to be done **before modeling can take place** because every Spark modeling routine expects the data to be in this form.\n",
    "\n",
    "You can do this by storing each of the values from a column as an entry in a vector. Then, from the model's point of view, every observation is a vector that contains all of the information about it and a label that tells the modeler what value that observation corresponds to. Because of this, the `pyspark.ml.feature` submodule contains a class called `VectorAssembler`. This `Transformer` takes all of the columns you specify and combines them into a new vector column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_assembler = VectorAssembler(inputCols=['genre_1_fact', 'genre_2_fact', 'genre_3_fact'],\n",
    "                                outputCol='features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a `Pipeline` to wrap all the `Transformer` and `Estimator` together\n",
    "\n",
    "Pipeline is a class in the `pyspark.ml` module that combines all the `Estimators` and `Transformers` created. This lets us reuse the same modeling process over and over again by wrapping it up in one simple object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_pipe = Pipeline(stages=[g1_indexer, g1_encoder,\n",
    "                               g2_indexer, g2_encoder,\n",
    "                               g3_indexer, g3_encoder,\n",
    "                               vec_assembler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the .fit() to create estimators and then .transform() to output result df\n",
    "ml_df_transformed = movies_pipe.fit(ml_df).transform(ml_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+----+------+---------+---------+--------+-------------+--------------+-------------+---------------+-------------+---------------+--------------------+\n",
      "|movieId|userId| tag|rating|  genre_1|  genre_2| genre_3|genre_1_index|  genre_1_fact|genre_2_index|   genre_2_fact|genre_3_index|   genre_3_fact|            features|\n",
      "+-------+------+----+------+---------+---------+--------+-------------+--------------+-------------+---------------+-------------+---------------+--------------------+\n",
      "| 117529|   103|null|     4|   Action|Adventure|   Drama|          0.0|(18,[0],[1.0])|          1.0| (17,[1],[1.0])|          3.0| (16,[3],[1.0])|(51,[0,19,38],[1....|\n",
      "|   2161|   103|null|     3|Adventure| Children| Fantasy|          3.0|(18,[3],[1.0])|          9.0| (17,[9],[1.0])|          4.0| (16,[4],[1.0])|(51,[3,27,39],[1....|\n",
      "|    356|   104|null|     4|   Comedy|    Drama| Romance|          1.0|(18,[1],[1.0])|          0.0| (17,[0],[1.0])|          2.0| (16,[2],[1.0])|(51,[1,18,37],[1....|\n",
      "|   1201|   105|null|     4|   Action|Adventure| Western|          0.0|(18,[0],[1.0])|          1.0| (17,[1],[1.0])|         11.0|(16,[11],[1.0])|(51,[0,19,46],[1....|\n",
      "|  55247|   105|null|     5|   Action|Adventure|   Drama|          0.0|(18,[0],[1.0])|          1.0| (17,[1],[1.0])|          3.0| (16,[3],[1.0])|(51,[0,19,38],[1....|\n",
      "|   5618|   105|null|     4|Adventure|Animation| Fantasy|          3.0|(18,[3],[1.0])|          7.0| (17,[7],[1.0])|          4.0| (16,[4],[1.0])|(51,[3,25,39],[1....|\n",
      "|    608|   105|null|     4|   Comedy|    Crime|   Drama|          1.0|(18,[1],[1.0])|          3.0| (17,[3],[1.0])|          3.0| (16,[3],[1.0])|(51,[1,21,38],[1....|\n",
      "|  61323|   105|null|     3|   Comedy|    Crime|   Drama|          1.0|(18,[1],[1.0])|          3.0| (17,[3],[1.0])|          3.0| (16,[3],[1.0])|(51,[1,21,38],[1....|\n",
      "|  70286|   105|null|     4|  Mystery|   Sci-Fi|Thriller|          9.0|(18,[9],[1.0])|          5.0| (17,[5],[1.0])|          0.0| (16,[0],[1.0])|(51,[9,23,35],[1....|\n",
      "|  81847|   105|null|     4|Animation| Children|  Comedy|          5.0|(18,[5],[1.0])|          9.0| (17,[9],[1.0])|          5.0| (16,[5],[1.0])|(51,[5,27,40],[1....|\n",
      "|    150|    11|null|     5|Adventure|    Drama|    IMAX|          3.0|(18,[3],[1.0])|          0.0| (17,[0],[1.0])|         13.0|(16,[13],[1.0])|(51,[3,18,48],[1....|\n",
      "|  56174|   111|null|     2|   Action|   Horror|  Sci-Fi|          0.0|(18,[0],[1.0])|          8.0| (17,[8],[1.0])|          1.0| (16,[1],[1.0])|(51,[0,26,36],[1....|\n",
      "|  63992|   111|null|     1|    Drama|  Fantasy| Romance|          2.0|(18,[2],[1.0])|         10.0|(17,[10],[1.0])|          2.0| (16,[2],[1.0])|(51,[2,28,37],[1....|\n",
      "|   8957|   111|null|     0|   Horror|  Mystery|Thriller|          6.0|(18,[6],[1.0])|         11.0|(17,[11],[1.0])|          0.0| (16,[0],[1.0])|(51,[6,29,35],[1....|\n",
      "|  72998|   112|null|     4|   Action|Adventure|  Sci-Fi|          0.0|(18,[0],[1.0])|          1.0| (17,[1],[1.0])|          1.0| (16,[1],[1.0])|(51,[0,19,36],[1....|\n",
      "|    377|   116|null|     3|   Action|  Romance|Thriller|          0.0|(18,[0],[1.0])|          2.0| (17,[2],[1.0])|          0.0| (16,[0],[1.0])|(51,[0,20,35],[1....|\n",
      "|   1210|   120|null|     5|   Action|Adventure|  Sci-Fi|          0.0|(18,[0],[1.0])|          1.0| (17,[1],[1.0])|          1.0| (16,[1],[1.0])|(51,[0,19,36],[1....|\n",
      "|  99114|   125|null|     4|   Action|    Drama| Western|          0.0|(18,[0],[1.0])|          0.0| (17,[0],[1.0])|         11.0|(16,[11],[1.0])|(51,[0,18,46],[1....|\n",
      "|   1619|    13|null|     3|Adventure|    Drama|     War|          3.0|(18,[3],[1.0])|          0.0| (17,[0],[1.0])|          8.0| (16,[8],[1.0])|(51,[3,18,43],[1....|\n",
      "|   1210|   132|null|     2|   Action|Adventure|  Sci-Fi|          0.0|(18,[0],[1.0])|          1.0| (17,[1],[1.0])|          1.0| (16,[1],[1.0])|(51,[0,19,36],[1....|\n",
      "+-------+------+----+------+---------+---------+--------+-------------+--------------+-------------+---------------+-------------+---------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ml_df_transformed.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For standard Train/Test split, it is recommended to be done **after** the transformations\n",
    "\n",
    "Use the DataFrame method `.randomSplit()` to split the transformed ml dataframe into two pieces. The exact ratio list (say `[0.6, 0.4]`) will split the records randomly with the designated ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = ml_df_transformed.randomSplit([0.6, 0.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+-----------+------------------+-------+---------+---------+------------------+------------------+------------------+\n",
      "|summary|          movieId|            userId|        tag|            rating|genre_1|  genre_2|  genre_3|     genre_1_index|     genre_2_index|     genre_3_index|\n",
      "+-------+-----------------+------------------+-----------+------------------+-------+---------+---------+------------------+------------------+------------------+\n",
      "|  count|            34581|             34581|       1212|             34533|  34581|    34581|    34581|             34581|             34581|             34581|\n",
      "|   mean|21200.52265695035|  324.878979786588|       null|3.3959111574436047|   null|     null|     null|1.5649923368323646|3.7205690986379802|3.5989994505653393|\n",
      "| stddev|35756.71951384241|183.80604503118502|       null|1.0770596153504473|   null|     null|     null|2.0795986324372713| 3.703135382337923| 3.538601170942013|\n",
      "|    min|                1|                 1|\"\"\"artsy\"\"\"|                 0| Action|Adventure|Animation|               0.0|               0.0|               0.0|\n",
      "|    max|            99992|                99|    zombies|                 5| Sci-Fi|      War|  Western|              16.0|              16.0|              16.0|\n",
      "+-------+-----------------+------------------+-----------+------------------+-------+---------+---------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+--------------------+------------------+-------+---------+---------+------------------+------------------+------------------+\n",
      "|summary|           movieId|            userId|                 tag|            rating|genre_1|  genre_2|  genre_3|     genre_1_index|     genre_2_index|     genre_3_index|\n",
      "+-------+------------------+------------------+--------------------+------------------+-------+---------+---------+------------------+------------------+------------------+\n",
      "|  count|             22616|             22616|                 859|             22577|  22616|    22616|    22616|             22616|             22616|             22616|\n",
      "|   mean|21208.063760169793| 325.8613813229572|                null| 3.399787394250786|   null|     null|     null|1.5554032543332155|3.7286876547576937|3.6040856031128405|\n",
      "| stddev|35964.071936322696|182.78807694002515|                null|1.0752086594646937|   null|     null|     null| 2.078884074985521| 3.678424690039412| 3.534254738265686|\n",
      "|    min|                 1|                 1|06 Oscar Nominate...|                 0| Action|Adventure|Animation|               0.0|               0.0|               0.0|\n",
      "|    max|             99917|                99|             zombies|                 5| Sci-Fi|      War|  Western|              16.0|              16.0|              16.0|\n",
      "+-------+------------------+------------------+--------------------+------------------+-------+---------+---------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Modeling Steps after ML-Ready Data is Prepared\n",
    "\n",
    "Using logistic regression as model to walk through the modeling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Create a LogisticRegression Estimator\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the evaluation submodule\n",
    "import pyspark.ml.evaluation as evals\n",
    "\n",
    "# Create a BinaryClassificationEvaluator\n",
    "evaluator = evals.BinaryClassificationEvaluator(metricName='areaUnderROC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the tuning submodule\n",
    "import pyspark.ml.tuning as tune\n",
    "import numpy as np\n",
    "\n",
    "# Create the parameter grid\n",
    "grid = tune.ParamGridBuilder()\n",
    "\n",
    "# Add the hyperparameter\n",
    "grid = grid.addGrid(lr.regParam, np.arange(0, .1, .01))\n",
    "grid = grid.addGrid(lr.elasticNetParam, [0, 1])\n",
    "\n",
    "# Build the grid\n",
    "grid = grid.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the CrossValidator\n",
    "cv = tune.CrossValidator(estimator=lr,\n",
    "                         estimatorParamMaps=grid,\n",
    "                         evaluator=evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit cross validation models\n",
    "models = cv.fit(train)\n",
    "\n",
    "# Extract the best model\n",
    "best_lr = models.bestModel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
