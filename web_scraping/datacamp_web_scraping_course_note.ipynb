{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scarping with `scrapy` in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. HTML and XPath Fundamentals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTML - HyperTest Markup Language\n",
    "\n",
    "### Structure of a HMTL:\n",
    "\n",
    "* HTML Tags:\n",
    "    * `<html> ... </html>`: root tag\n",
    "    * `<body> ... </body>`: body tag\n",
    "    * `<div> ... </div>`: section tag\n",
    "    * `<p> ... </p>`: paragraph tag\n",
    "    * `<a> ... </a>`: hyperlink tag\n",
    "* HTML tree: structure of HTML\n",
    "    * **child**, **parent**, **sibling**, **generation**, **decendant**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTML Specific Syntax\n",
    "\n",
    "Typical structure of a HTML element:\n",
    "\n",
    "```html\n",
    "<tag-name attrib-name=\"attrib info\">\n",
    "    ..element contents.\n",
    "</tag-name>\n",
    "```\n",
    "\n",
    "### For example:\n",
    "\n",
    "```html\n",
    "<div id=\"unique-id\" class=\"some class\">\n",
    "    ..div element contents..\n",
    "</div>\n",
    "```\n",
    "* `id` is used to be unique for the specific element.\n",
    "* `class` is also used to identify the element; a tag can belong to multiple attributes. In this example, the classes are `\"some\"` and `\"class\"`\n",
    "\n",
    "### Another example:\n",
    "\n",
    "```html\n",
    "<a href=\"https://somewebsite.com\">\n",
    "    This text links to the website\n",
    "</a>\n",
    "```\n",
    "* For an `a` tag, attribute `href` is the hyperlink directed to\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro to XPath Notation\n",
    "\n",
    "The **XPath** notation identifies the location of any elements in an html object. Think of this **XPath** notation as *paths for html elements*\n",
    "\n",
    "1.A single forward-slash `/` to more forward one generation\n",
    "\n",
    "2.Tag-names between slashes to give direction to which element(s)\n",
    "\n",
    "3.Use `//` to look in **all forward generations** instead of single forward for the specific tag-name\n",
    "\n",
    "4.`[]` to identify which of the selected siblings to choose (starting from 1)\n",
    "\n",
    "5.Use `@` sign to signify an attribute. Use `[]` to wrap the condition as a selection. For instance `//div[@id=\"uid\"]` will look for **all** `div` element that has an `id` attribute equal to `\"uid\"`.\n",
    "\n",
    "6.Use `*` as the wildcard to select all elements in a forward generation.\n",
    "\n",
    "7.Use `@` directly after slashes to refer to the attribute itself. `/@attri_name` selects the attributes of current element, while `//@attri_name` selects the attributes of all forward generations\n",
    "\n",
    "8.Use `text()` function within XPath to signify only texts of an HTML element. Therefore, `/text()` extracts chunks of text in current element, while `//text()` extract all chunks of texts in decedants from forward generations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. XPath and Selectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XPathology\n",
    "\n",
    "**1. Be cautious around `[number]` cases**\n",
    "\n",
    "When `//` searches across all elements for a tag-name, adding `[n]` to the path will **identify the *n*th element of each selected group of siblings**. Therefore, if `<p> ... </p>` is present in 2 different generation levels, then `\"//p[1]\"` selects the 1st `p` element in each level.\n",
    "\n",
    "**2. Using `*` with slashes**\n",
    "\n",
    "When using `/*`, XPath points to **direct child elements**. When using `//*`, XPath points to **all decendant elements**.\n",
    "\n",
    "**3. `contains(@attri-name, \"string-expr\")` function vs `[]`**\n",
    "\n",
    "This function searches the attribute that has the `\"string-expr\"` as a substring in its attribute. Using direct `[ ]` is looking for an exact match instead.\n",
    "\n",
    "For instance, if an element is:\n",
    "\n",
    "```html\n",
    "<p class='class-1 class-2' id='id-1'>Paragraph 1</p>\n",
    "```\n",
    "\n",
    "Then search using `contains(@class, 'class-1')` or `[@class=\"class-1 class-2\"]` will return this element.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Scrapy` `Selector` with XPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scrapy import Selector\n",
    "\n",
    "# provided a html as string\n",
    "html=\"\"\"\n",
    "<html>\n",
    "  <body>\n",
    "    <div class=\"hello datacamp\">\n",
    "      <p>Hello World!</p>\n",
    "    </div>\n",
    "    <p>Enjoy DataCamp!</p>\n",
    "  </body>\n",
    "</html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object sel has class <class 'scrapy.selector.unified.Selector'>\n",
      "returned object from sel.xpath('//p') is <class 'scrapy.selector.unified.SelectorList'>\n",
      "Below contents are extracted with .extract():\n",
      "<p>Hello World!</p>\n",
      "<p>Enjoy DataCamp!</p>\n"
     ]
    }
   ],
   "source": [
    "# instantiate a Selector object form the string\n",
    "sel = Selector(text=html)\n",
    "print(\"object sel has class {}\".format(type(sel)))\n",
    "\n",
    "# call .xpath() method within a Selector object\n",
    "# to create a SelectorList of Selector objects\n",
    "sel_p_list = sel.xpath(\"//p\")\n",
    "print(\"returned object from sel.xpath('//p') is {}\".format(\n",
    "    type(sel_p_list)))\n",
    "\n",
    "# call .extract() method within a SelectorList\n",
    "# to get to list of string from each Selector\n",
    "# in the SelectorList\n",
    "str_p_list = sel_p_list.extract()\n",
    "print(\"Below contents are extracted with .extract():\\n{}\".format(\n",
    "    \"\\n\".join(str_p_list)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chaining .xpath() methods. if not starting from root\n",
    "# add \".\" at the begining of the chain\n",
    "assert sel.xpath('/html/body//*').extract() == \\\n",
    "    sel.xpath('/html').xpath('./body//*').extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting the HTML (easy way)\n",
    "\n",
    "**In oder to examine the HTML of a webpage**\n",
    "\n",
    "1.Examining the \"Source\" of any website will display the HTML Code for the page.\n",
    "\n",
    "2.Inspecting Element will display the corresponding element's (hovered over by mouse) HTML raw code\n",
    "\n",
    "3.Use Python `requests` module can quickly download the raw HTML code of the specific web page by calling `requests.get(url_text).content`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. CSS Locators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difference between XPath and CSS?\n",
    "\n",
    "1.`/` is replaced by `>` (except first character, which will be ignored)\n",
    "\n",
    "So **XPath** `/html/body/div` equals **CSS** `html > body > div`\n",
    "\n",
    "2.`//` is replaced by a blank space (except first character, which will be ignored)\n",
    "\n",
    "So **XPath** `//div/span//p` equals **CSS** `div > span p`\n",
    "\n",
    "3.`[N]` replaced by `:nth-of-type(N)`\n",
    "\n",
    "So **XPath** `//div/p[2]` equals **CSS** `div > p:nth-of-type(2)`\n",
    "\n",
    "4.To find an element by class, use a period `.`. To find an element by id, use a pound sign `#`\n",
    "\n",
    "* **Note:** This is a true \"matching\", meaning it's not looking for string matching in XPath anymore. Instead, it looks for elements that has the same class / id without the need to do string exact match. This matchi s more superior than **XPath**'s `[@attri='exact_string']` AND `contains(@attri, 'sub_string')`\n",
    "\n",
    "5.Use `*` as wildcard\n",
    "\n",
    "6.Use `<css-to-element>::attr(attr-name)` to access attribute of elements\n",
    "\n",
    "So **XPath** `//div[@id='uid']/a/@href` equals **CSS** `div#uid > a::attr(hred)`\n",
    "\n",
    "7.Use `<css-to-element>::text` to access text of **current element**. Use `<css-to-element> ::text` to access text of all future elements. (Notice the space in second case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  How to use `scrapy` with CSS locator string?\n",
    "\n",
    "Simply call the `.css('CSS_match_string`)` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<div class=\"hello datacamp\">\\n      <p>Hello World!</p>\\n    </div>',\n",
       " '<p>Hello World!</p>',\n",
       " '<p>Enjoy DataCamp!</p>']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel.css(\"html>body *\").extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `Response` objects instead of `Selector` object"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
